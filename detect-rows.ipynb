{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find rows in a column\n",
    "\n",
    "Use Tesseract to separate columns into rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "import pytesseract\n",
    "from statistics import mean\n",
    "import math\n",
    "import statistics\n",
    "import re\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These OCR image preprocessing steps are based on https://stackoverflow.com/a/43493383\n",
    "# I don't really understand why this particular combination of filters works, but it does seem to improve OCR results\n",
    "\n",
    "BINARY_THRESHOLD = 200\n",
    "\n",
    "def process_image_for_ocr(file_path):\n",
    "    # TODO : Implement using opencv\n",
    "    temp_filename = set_image_dpi(file_path)\n",
    "    im_new = remove_noise_and_smooth(temp_filename)\n",
    "    return im_new\n",
    "\n",
    "\n",
    "def set_image_dpi(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    #length_x, width_y = im.size\n",
    "    #factor = max(1, int(IMAGE_SIZE / length_x))\n",
    "    #size = factor * length_x, factor * width_y\n",
    "    # size = (1800, 1800)\n",
    "    #im_resized = im.resize(size, Image.ANTIALIAS)\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')\n",
    "    temp_filename = temp_file.name\n",
    "    im.save(temp_filename, dpi=(300, 300))\n",
    "    return temp_filename\n",
    "\n",
    "\n",
    "def image_smoothening(img):\n",
    "    ret1, th1 = cv2.threshold(img, BINARY_THRESHOLD, 255, cv2.THRESH_BINARY)\n",
    "    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    blur = cv2.GaussianBlur(th2, (1, 1), 0)\n",
    "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return th3\n",
    "\n",
    "\n",
    "def remove_noise_and_smooth(file_name):\n",
    "    img = cv2.imread(file_name, 0)\n",
    "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 41, 3)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    img = image_smoothening(img)\n",
    "    or_image = cv2.bitwise_or(img, closing)\n",
    "    return or_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_points(points, distance):\n",
    "    '''\n",
    "    Cluster together nearby points.\n",
    "    '''\n",
    "    clusters = []\n",
    "    start = 0\n",
    "    cluster = []\n",
    "    for x in points:\n",
    "        if x < start + distance:\n",
    "            cluster.append(x)\n",
    "        else:\n",
    "            if cluster:\n",
    "                clusters.append(sorted(cluster))\n",
    "            cluster = [x]\n",
    "        start = x\n",
    "    clusters.append(cluster)\n",
    "    return clusters\n",
    "\n",
    "def find_rows(image_name, image_path, output_dir='data'):\n",
    "    '''\n",
    "    Use Tesseract to detect lines of text, then use those lines to crop out individual rows from the column.\n",
    "    '''\n",
    "    row_dir = os.path.join(output_dir, 'rows')\n",
    "    os.makedirs(row_dir, exist_ok=True)\n",
    "    col = cv2.imread(image_path)\n",
    "    h, w = col.shape[:2]\n",
    "    temp_img = process_image_for_ocr(image_path)\n",
    "    \n",
    "    # We're interested in the printed labels on the left of each column\n",
    "    # Here we crop off the right side of the image to remove some of the handwritten text\n",
    "    # This simplifies the OCR results\n",
    "    temp_img = temp_img[0:h, 0:int(round(w * 0.6))]\n",
    "    \n",
    "    # Get OCR results as a Pandas dataframe\n",
    "    results = pytesseract.image_to_data(temp_img, output_type=pytesseract.Output.DATAFRAME)\n",
    "    # print(results.loc[results['level'] == 5])\n",
    "    \n",
    "    # Level 4 of the OCR results are individual words\n",
    "    # Get all the unique 'top' positions of words\n",
    "    lines = pd.unique(results.loc[results['level'] == 4]['top'])\n",
    "    \n",
    "    # Sort the 'top' values\n",
    "    lines = sorted(lines)\n",
    "    \n",
    "    # Get an approximate line height from the median of the text height values\n",
    "    line_height = int(round(results.loc[~results['text'].isna()]['height'].median()))\n",
    "    # print(line_height)\n",
    "    \n",
    "    # Group nearby lines into clusters based on the line height\n",
    "    clusters = cluster_points(lines, line_height)\n",
    "    \n",
    "    # Make a copy of the image\n",
    "    col2 = col.copy()\n",
    "    \n",
    "    # window = int(round(line_height * .8))\n",
    "    \n",
    "    # Get the header row\n",
    "    header = col[0:clusters[1][0], 0:w]\n",
    "    #header = col[0:clusters[1]]\n",
    "    header_height = header.shape[0]\n",
    "    # cv2.imwrite('{}/columns/rows/{}-header.jpg'.format(output_dir, image_name[:-4]), header)\n",
    "    cells = [l[0] for l in clusters[1:]]\n",
    "    #cells = clusters[1:]\n",
    "    \n",
    "    for index, cell in enumerate(cells):\n",
    "        cv2.line(col2,(0, cell),(w, cell),(255,0,0),3)\n",
    "        try:\n",
    "            # Get next cell top, add a margin to make sure we get all the content\n",
    "            next_cell = cells[index+1] + int(round(line_height/2))\n",
    "        except IndexError:\n",
    "            # If we're at the end, just go to the bttom of the column\n",
    "            next_cell = h\n",
    "        \n",
    "        # Add a margin at the top of the cell\n",
    "        if cell > line_height:\n",
    "            row = col[(cell - line_height):next_cell, 0:w]\n",
    "        else:\n",
    "            row = col[0:next_cell, 0:w]\n",
    "        #combined = np.concatenate((header, row), axis=0)\n",
    "        # cv2.line(combined,(0, header_height),(w, header_height),(255,0,0),3)\n",
    "        #cv2.imwrite('{}/columns/rows/{}-{}.jpg'.format(output_dir, image_name[:-4], index), combined)\n",
    "        cv2.imwrite('{}/{}-{}.jpg'.format(row_dir, image_name[:-4], index), row)\n",
    "    # cv2.imwrite('{}/{}-rows.jpg'.format(row_dir, image_name[:-4]), col2)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = find_rows('N193-113_0014-col-1.jpg', '/Users/tim/mycode/stock-exchange/notebooks/processed/1929/columns/N193-113_0014-col-1.jpg', 'processed/testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_dir = '/Users/tim/mycode/stock-exchange/notebooks/processed/1929/columns'\n",
    "for img_name in [i for i in os.listdir(columns_dir) if i[-4:] == '.jpg']:\n",
    "    img_path = os.path.join(columns_dir, img_name)\n",
    "    find_rows(img_name, img_path, 'processed/1929')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
